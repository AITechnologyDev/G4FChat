import uuid
import g4f
import json
import logging
import sys
import time
import inspect
import threading
import os
import re
from threading import Lock, Event
from g4f import Provider
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.markdown import Markdown
from rich.style import Style
from pygments import highlight
from pygments.lexers import get_lexer_by_name, TextLexer
from pygments.formatters import TerminalFormatter

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    filename='ai_chat.log',
    filemode='a'
)
logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Rich
console = Console()
error_style = Style(color="red", bold=True)
success_style = Style(color="green", bold=True)
warning_style = Style(color="yellow", bold=True)
info_style = Style(color="blue", bold=True)
ai_style = Style(color="cyan", bold=True)
code_style = Style(color="magenta")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
MODEL_FILE = 'user_models.json'
USER_CHATS_FILE = 'user_chats.json'
LANG_FILE = 'user_lang.json'

# –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
user_models_cache = {}
user_chats_cache = {}
user_lang_cache = {}
active_providers = []
provider_classes = {}
stats = {
    'total_messages': 0,
    'saved_code_blocks': 0,
    'active_chats': 0,
    'last_activity': time.time()
}

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
cache_lock = Lock()

# –ß–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
BLACKLISTED_PROVIDERS = ['BlackForestLabs_Flux1Dev', 'DeepInfra', 'FlowGpt', 'Free2GPT', 'ImageLabs', 'HuggingFace', 'PollinationsImage']

# –°–ª–æ–≤–∞—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–∞
TRANSLATIONS = {
    'en': {
        'welcome_menu': "Welcome",
        'welcome': "Console AI Chat",
        'developer': "Developer",
        'github': "GitHub",
        'help_title': "Help",
        'commands': "Commands",
        'new_chat': "Create new chat",
        'switch_chat': "Switch chat",
        'delete_chat': "Delete chat",
        'list_chats': "Show chat list",
        'set_model': "Set model",
        'current_model': "Current model",
        'list_models': "Show available models",
        'list_providers': "Show active providers",
        'system_status': "System status",
        'exit': "Exit program",
        'help': "Show help",
        'lang': "Set language",
        'stats': "Show usage stats",
        'chat_prompt': "You",
        'start_chat': "Just type a message or question",
        'ai_prompt': "AI",
        'thinking': "Model reflections",
        'saving_code': "Saved code blocks",
        'generating': "Generating response...",
        'model_set': "Model set",
        'model_error': "Model not available",
        'chat_created': "New chat created and selected",
        'chat_switched': "Switched to chat",
        'chat_not_found': "Chat not found",
        'chat_deleted': "Chat deleted",
        'no_chats': "You have no chats yet",
        'your_chats': "Your Chats",
        'current_model_title': "Current Model",
        'available_models': "Available models",
        'active_providers': "Active providers",
        'system_status_title': "System status",
        'exit_confirmation': "Exiting program...",
        'unknown_command': "Unknown command",
        'gen_error': "Response generation error",
        'main_error': "An error occurred. Continuing...",
        'code_saved': "Saved {} code block(s)",
        'stats_title': "Usage Statistics",
        'total_messages': "Total messages",
        'saved_blocks': "Saved code blocks",
        'active_chats': "Active chats",
        'last_activity': "Last activity",
        'time_format': "%Y-%m-%d %H:%M",
        'lang_set': "Language set",
        'invalid_lang': "Invalid language. Use 'en' or 'ru'",
        'providers_title': "Active Providers",
        'total_providers': "Total providers",
        'saved_code_location': "Code saved to:"
    },
    'ru': {
        'welcome_menu': "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å",
        'welcome': "–ö–æ–Ω—Å–æ–ª—å–Ω—ã–π AI –ß–∞—Ç",
        'developer': "–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫",
        'github': "GitHub",
        'help_title': "–ü–æ–º–æ—â—å",
        'commands': "–ö–æ–º–∞–Ω–¥—ã",
        'new_chat': "–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π —á–∞—Ç",
        'switch_chat': "–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —á–∞—Ç",
        'delete_chat': "–£–¥–∞–ª–∏—Ç—å —á–∞—Ç",
        'list_chats': "–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ —á–∞—Ç–æ–≤",
        'set_model': "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å",
        'current_model': "–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å",
        'list_models': "–ü–æ–∫–∞–∑–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏",
        'list_providers': "–ü–æ–∫–∞–∑–∞—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã",
        'system_status': "–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã",
        'exit': "–í—ã–π—Ç–∏ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã",
        'help': "–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É",
        'lang': "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —è–∑—ã–∫",
        'stats': "–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É",
        'chat_prompt': "–í—ã",
        'start_chat': "–ü—Ä–æ—Å—Ç–æ –≤–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –≤–æ–ø—Ä–æ—Å",
        'ai_prompt': "–ò–ò",
        'thinking': "–†–∞–∑–º—ã—à–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏",
        'saving_code': "–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏ –∫–æ–¥–∞",
        'generating': "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...",
        'model_set': "–ú–æ–¥–µ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞",
        'model_error': "–ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞",
        'chat_created': "–ù–æ–≤—ã–π —á–∞—Ç —Å–æ–∑–¥–∞–Ω –∏ –≤—ã–±—Ä–∞–Ω",
        'chat_switched': "–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–æ –Ω–∞ —á–∞—Ç",
        'chat_not_found': "–ß–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω",
        'chat_deleted': "–ß–∞—Ç —É–¥–∞–ª–µ–Ω",
        'no_chats': "–£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç —á–∞—Ç–æ–≤",
        'your_chats': "–í–∞—à–∏ —á–∞—Ç—ã",
        'current_model_title': "–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å",
        'available_models': "–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏",
        'active_providers': "–ê–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã",
        'system_status_title': "–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã",
        'exit_confirmation': "–í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã...",
        'unknown_command': "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞",
        'gen_error': "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞",
        'main_error': "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º...",
        'code_saved': "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞: {}",
        'stats_title': "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è",
        'total_messages': "–í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π",
        'saved_blocks': "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞",
        'active_chats': "–ê–∫—Ç–∏–≤–Ω—ã—Ö —á–∞—Ç–æ–≤",
        'last_activity': "–ü–æ—Å–ª–µ–¥–Ω—è—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å",
        'time_format': "%d.%m.%Y %H:%M",
        'lang_set': "–Ø–∑—ã–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω",
        'invalid_lang': "–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —è–∑—ã–∫. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ 'en' –∏–ª–∏ 'ru'",
        'providers_title': "–ê–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã",
        'total_providers': "–í—Å–µ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤",
        'saved_code_location': "–ö–æ–¥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤:"
    }
}

def tr(key, lang='en'):
    """–ü–æ–ª—É—á–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ –ø–æ –∫–ª—é—á—É"""
    return TRANSLATIONS.get(lang, {}).get(key, key)

def get_user_lang(user_id):
    """–ü–æ–ª—É—á–∏—Ç—å —è–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    global user_lang_cache
    user_id = str(user_id)
    
    if not user_lang_cache:
        try:
            if os.path.exists(LANG_FILE):
                with open(LANG_FILE, 'r') as f:
                    user_lang_cache = json.load(f)
            else:
                user_lang_cache = {}
        except Exception as e:
            logger.error(f"Language load error: {e}")
            user_lang_cache = {}
    
    return user_lang_cache.get(user_id, 'en')

def save_user_lang(user_id, lang):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —è–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    global user_lang_cache
    user_id = str(user_id)
    
    with cache_lock:
        user_lang_cache[user_id] = lang
        try:
            with open(LANG_FILE, 'w') as f:
                json.dump(user_lang_cache, f)
        except Exception as e:
            logger.error(f"Error saving language: {e}")

# –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
def get_all_providers():
    providers = []
    for name, obj in inspect.getmembers(g4f.Provider):
        if inspect.isclass(obj) and issubclass(obj, g4f.Provider.BaseProvider):
            providers.append(obj)
    return providers

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
def init_providers():
    global active_providers, provider_classes
    with cache_lock:
        if active_providers:
            return active_providers
            
        logger.info("Initializing providers...")
        with console.status("[bold blue]Initializing providers...[/]", spinner="dots"):
            all_providers = get_all_providers()
            active_providers = []
            provider_classes = {}
            
            for provider in all_providers:
                try:
                    provider_name = provider.__name__
                    
                    if provider_name in BLACKLISTED_PROVIDERS:
                        logger.info(f"Skipping blacklisted provider: {provider_name}")
                        continue
                    
                    if (hasattr(provider, 'working') and provider.working and 
                        (hasattr(provider, 'url') or hasattr(provider, 'model'))):
                        active_providers.append(provider)
                        provider_classes[provider_name] = provider
                        logger.info(f"Added provider: {provider_name}")
                except Exception as e:
                    logger.warning(f"Provider validation error {provider.__name__}: {str(e)[:100]}")
            
            if not active_providers:
                backup_providers = [g4f.Provider.You]
                for provider in backup_providers:
                    if provider.__name__ not in BLACKLISTED_PROVIDERS:
                        active_providers.append(provider)
                        provider_classes[provider.__name__] = provider
                logger.warning(f"Using backup providers: {[p.__name__ for p in active_providers]}")
            
            logger.info(f"Active providers: {len(active_providers)}")
        return active_providers

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
def load_user_models():
    global user_models_cache
    with cache_lock:
        if user_models_cache:
            return user_models_cache
            
        try:
            if os.path.exists(MODEL_FILE):
                with open(MODEL_FILE, 'r') as f:
                    user_models_cache = json.load(f)
            else:
                user_models_cache = {}
        except Exception as e:
            logger.error(f"Model load error: {e}")
            user_models_cache = {}
        return user_models_cache

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
def save_user_models(data):
    global user_models_cache
    with cache_lock:
        user_models_cache = data
        try:
            with open(MODEL_FILE, 'w') as f:
                json.dump(data, f)
        except Exception as e:
            logger.error(f"Error saving models: {e}")

# –ó–∞–≥—Ä—É–∑–∫–∞ —á–∞—Ç–æ–≤
def load_user_chats():
    global user_chats_cache, stats
    with cache_lock:
        if user_chats_cache:
            return user_chats_cache
            
        try:
            if os.path.exists(USER_CHATS_FILE):
                with open(USER_CHATS_FILE, 'r', encoding='utf-8') as f:
                    user_chats_cache = json.load(f)
                    
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                stats['active_chats'] = 0
                for user_id, user_data in user_chats_cache.items():
                    chats = user_data.get("chats", {})
                    stats['active_chats'] += len(chats)
                    
                    for chat_id, chat_data in chats.items():
                        stats['total_messages'] += len(chat_data.get("history", []))
            else:
                user_chats_cache = {}
        except Exception as e:
            logger.error(f"Chat load error: {e}")
            user_chats_cache = {}
        return user_chats_cache

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–∞—Ç–æ–≤
def save_user_chats(data):
    global user_chats_cache, stats
    with cache_lock:
        user_chats_cache = data
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats['active_chats'] = 0
        stats['total_messages'] = 0
        for user_id, user_data in data.items():
            chats = user_data.get("chats", {})
            stats['active_chats'] += len(chats)
            
            for chat_id, chat_data in chats.items():
                stats['total_messages'] += len(chat_data.get("history", []))
        
        stats['last_activity'] = time.time()
        
        try:
            with open(USER_CHATS_FILE, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Error saving chats: {e}")

# –ü–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
def get_supported_models():
    return {
        "OpenAI": {
            'gpt-3.5-turbo',
            'gpt-4',
            'gpt-4o',
            'gpt-4o-mini',
            'gpt-4o-search',
            'gpt-4o-mini-search',
            'gpt-4-1',
            'gpt-4.1-mini',
            'gpt-4.1-nano',
            'gpt-4.5',
            'o1',
            'o1-mini',
            'o1-pro',
            'o3',
            'o3-mini',
            'o3-mini-high',
            'o4-mini',
            'o4-mini-high'
        },
        "Llama": {
            'llama-2-7b',
            'llama-2-70b',
            'llama-3-8b',
            'llama-3.1-8b',
            'llama-3.1-70b',
            'llama-3.1-405b',
            'llama-3.2-1b',
            'llama-3.2-3b',
            'llama-3.2-11b',
            'llama-3.2-90b',
            'llama-3.3-70b'
        },
        "Mistral": {
            'mistral-nemo',
            'mistral-7b',
            'mistral-small-24b',
            'mixtral-8x7b'
        },
        "Microsoft": {
            'phi-4'
        },
        "Google": {
            'gemini-1.5-flash',
            'gemini-1.5-pro',
            'gemini-2.0-flash',
            'gemini-2.0-pro-exp',
            'gemini-2.5-flash',
            'gemini-2.5-pro'
        },
        "Qwen": {
            'qwen-1.5-7b',
            'qwen-2-72b',
            'qwen-2.5',
            'qwen-2.5-7b',
            'qwen-2.5-72b',
            'qwen-2.5-coder-32b',
            'qwen-3-32b',
            'qwen-3-30b',
            'qwq-32b'
        },
        "DeepSeek": {
            'deepseek-v3',
            'deepseek-r1'
        },
        "xAI": {
            'grok-2',
            'grok-2-mini',
            'early-grok-3',
            'grok-3',
            'grok-3-beta',
            'grok3-mini',
            'grok-3-mini-beta',
            'grok-3-mini-high',
            'grok-3-fast',
            'grok-3-fast-mini',
            'grok-3-r1',
            'grok-3-thinking'
        },
        "Perplexity": {
            'sonar-pro',
            'sonar',
            'sonar-reasoning-pro',
            'sonar-reasoning'
        },
        " Anthropic": {
            'claude-3-7-sonnet',
            'claude-3.5-sonnet',
            'claude-3-sonnet',
            'claude-3-opus',
            'claude-3-haiku'
        }
    }

# –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–¥–∞
def save_code_blocks(response_text, chat_id, lang='en'):
    code_pattern = r'```(\w+)?\n([\s\S]*?)\n```'
    matches = re.findall(code_pattern, response_text)
    
    if not matches:
        return response_text
        
    saved_files = []
    for idx, match in enumerate(matches):
        lang_ext, code = match
        if not lang_ext:
            lang_ext = 'txt'
            
        filename = f"saved_code/{chat_id}_{int(time.time())}_{idx}.{lang_ext}"
        os.makedirs("saved_code", exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(code)
        saved_files.append(filename)
    
    if saved_files:
        global stats
        stats['saved_code_blocks'] += len(saved_files)
        console.print(f"\n[green]üíæ {tr('saved_code_location', lang)}[/]")
        for file in saved_files:
            console.print(f"  ‚Üí [link=file://{os.path.abspath(file)}]{file}[/]")
        console.print(f"[dim]{tr('code_saved', lang).format(len(saved_files))}[/]")
    
    # –£–±–∏—Ä–∞–µ–º –±–ª–æ–∫–∏ –∫–æ–¥–∞ –∏–∑ –æ—Ç–≤–µ—Ç–∞
    return re.sub(code_pattern, '', response_text)

# –ü–æ–¥—Å–≤–µ—Ç–∫–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
def highlight_code(text):
    code_pattern = r'```(\w+)?\n([\s\S]*?)\n```'
    
    def replacer(match):
        lang = match.group(1) or 'text'
        code = match.group(2)
        
        try:
            lexer = get_lexer_by_name(lang, stripall=True)
        except:
            lexer = TextLexer()
            
        formatter = TerminalFormatter()
        highlighted = highlight(code, lexer, formatter)
        return highlighted
    
    return re.sub(code_pattern, replacer, text)

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
def generate_response(user_id: int, chat_id: str, messages: list) -> str:
    user_models = load_user_models()
    model_name = user_models.get(str(user_id), 'gpt-4o')
    
    all_chats = load_user_chats()
    user_chats = all_chats.get(str(user_id), {})
    chat_data = user_chats.get("chats", {}).get(chat_id, {})
    
    saved_provider = chat_data.get("provider")
    providers = init_providers()
    provider_errors = []
    
    # –ü—Ä–æ–±—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
    if saved_provider:
        try:
            provider_class = provider_classes.get(saved_provider)
            if provider_class:
                logger.info(f"Using saved provider: {saved_provider}")
                response = g4f.ChatCompletion.create(
                    model=model_name,
                    messages=messages,
                    provider=provider_class,
                    timeout=60,
                    auto_continue=True
                )
                full_response = ""
                for chunk in response:
                    if isinstance(chunk, str):
                        full_response += chunk
                    if len(full_response) > 10000:
                        break
                
                if full_response.strip():
                    return full_response
        except Exception as e:
            error_msg = f"{saved_provider}: {str(e)[:100]}"
            provider_errors.append(error_msg)
            logger.warning(f"Error in saved provider: {error_msg}")
            chat_data["provider"] = None
            user_chats.setdefault("chats", {})[chat_id] = chat_data
            all_chats[str(user_id)] = user_chats
            save_user_chats(all_chats)

    # –ü—Ä–æ–±—É–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
    for provider in providers:
        try:
            if saved_provider and provider.__name__ == saved_provider:
                continue
                
            logger.info(f"Trying provider: {provider.__name__}")
            response = g4f.ChatCompletion.create(
                model=model_name,
                messages=messages,
                provider=provider,
                timeout=60,
                auto_continue=True
            )
            full_response = ""
            for chunk in response:
                if isinstance(chunk, str):
                    full_response += chunk
                if len(full_response) > 10000:
                    break
            
            if full_response.strip():
                chat_data["provider"] = provider.__name__
                user_chats.setdefault("chats", {})[chat_id] = chat_data
                all_chats[str(user_id)] = user_chats
                save_user_chats(all_chats)
                return full_response
        except Exception as e:
            error_msg = f"{provider.__name__}: {str(e)[:100]}"
            provider_errors.append(error_msg)
            logger.warning(f"Provider error: {error_msg}")
            time.sleep(0.1)
    
    error_details = "\n".join(provider_errors[-5:])
    return f"‚ö†Ô∏è All providers unavailable. Try later or change model.\n\nErrors:\n{error_details}"

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π –º–æ–¥–µ–ª–∏
def process_model_thinking(response_text, lang='en'):
    thinking_pattern = r'<thinking>(.*?)</thinking>'
    matches = re.findall(thinking_pattern, response_text, re.DOTALL)
    
    if matches:
        console.print(f"\n[bold yellow]üí≠ {tr('thinking', lang)}:[/]")
        for i, thought in enumerate(matches, 1):
            thought = thought.strip()
            if thought:
                console.print(f"[dim]{i}.[/] {thought}")
        
        response_text = re.sub(thinking_pattern, '', response_text, flags=re.DOTALL).strip()
    
    return response_text

# –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É
def show_help(user_id):
    lang = get_user_lang(user_id)
    
    help_text = (
        f"[bold cyan]ü§ñ {tr('welcome', lang)} (g4f v0.5.7.5)[/]\n"
        f"[bold]{tr('developer', lang)}:[/] AiTechnologyDev\n"
        f"[bold]GitHub:[/] [link=https://github.com/AITechnologyDev]https://github.com/AITechnologyDev[/]\n\n"
        f"[bold]{tr('commands', lang)}:[/]\n"
        f"  [bold]/newchat[/]  - {tr('new_chat', lang)}\n"
        f"  [bold]/usechat[/]  - {tr('switch_chat', lang)}\n"
        f"  [bold]/delchat[/]  - {tr('delete_chat', lang)}\n"
        f"  [bold]/chats[/]    - {tr('list_chats', lang)}\n"
        f"  [bold]/setmodel[/] - {tr('set_model', lang)}\n"
        f"  [bold]/mymodel[/]  - {tr('current_model', lang)}\n"
        f"  [bold]/models[/]   - {tr('list_models', lang)}\n"
        f"  [bold]/providers[/]- {tr('list_providers', lang)}\n"
        f"  [bold]/status[/]   - {tr('system_status', lang)}\n"
        f"  [bold]/lang[/]     - {tr('lang', lang)} (en/ru)\n"
        f"  [bold]/stats[/]    - {tr('stats', lang)}\n"
        f"  [bold]/exit[/]     - {tr('exit', lang)}\n"
        f"  [bold]/help[/]     - {tr('help', lang)}\n\n"
        f"[bold cyan]{tr('start_chat', lang)}:[/]"
    )
    
    console.print(Panel(
        help_text,
        title=tr('help_title', lang),
        title_align="left",
        border_style="cyan",
        padding=(1, 2),
        width=80
    ))

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏
def set_model(user_id, model_name):
    lang = get_user_lang(user_id)
    
    try:
        supported_models = get_supported_models()
        
        if model_name not in supported_models:
            console.print(f"[red]‚ùå {tr('model_error', lang)}. /models {tr('list_models', lang).lower()}[/]")
            return False
        
        user_models = load_user_models()
        user_models[str(user_id)] = model_name
        save_user_models(user_models)
        
        console.print(f"[green]‚úÖ {tr('model_set', lang)}:[/] [bold]{model_name}[/]")
        return True
    except Exception as e:
        logger.error(f"Model set error: {e}")
        console.print(f"[red]‚ùå {tr('model_error', lang)}[/]")
        return False

# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —á–∞—Ç–∞
def new_chat(user_id):
    lang = get_user_lang(user_id)
    user_id = str(user_id)
    chats = load_user_chats()
    user_chats = chats.get(user_id, {})
    chat_list = user_chats.get("chats", {})
    chat_id = str(uuid.uuid4())[:8]
    
    chat_list[chat_id] = {
        "history": [{"role": "system", "content": "You are a friendly and helpful AI assistant."}],
        "provider": None
    }
    
    user_chats["chats"] = chat_list
    user_chats["active"] = chat_id
    chats[user_id] = user_chats
    save_user_chats(chats)
    
    global stats
    stats['active_chats'] += 1
    
    console.print(f"[green]üÜï {tr('chat_created', lang)}:[/] [bold]{chat_id}[/]")
    return chat_id

# –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —á–∞—Ç–∞
def use_chat(user_id, chat_id):
    lang = get_user_lang(user_id)
    
    try:
        user_id = str(user_id)
        chats = load_user_chats()
        user_chats = chats.get(user_id, {})
        chat_list = user_chats.get("chats", {})
        if chat_id in chat_list:
            user_chats["active"] = chat_id
            chats[user_id] = user_chats
            save_user_chats(chats)
            console.print(f"[green]‚úÖ {tr('chat_switched', lang)}:[/] [bold]{chat_id}[/]")
            return True
        else:
            console.print(f"[red]‚ùå {tr('chat_not_found', lang)}[/]")
            return False
    except Exception:
        console.print(f"[red]‚ùå {tr('chat_not_found', lang)}[/]")
        return False

# –£–¥–∞–ª–µ–Ω–∏–µ —á–∞—Ç–∞
def del_chat(user_id, chat_id):
    lang = get_user_lang(user_id)
    
    try:
        user_id = str(user_id)
        chats = load_user_chats()
        user_chats = chats.get(user_id, {})
        chat_list = user_chats.get("chats", {})
        if chat_id in chat_list:
            del chat_list[chat_id]
            if user_chats.get("active") == chat_id:
                new_active = next(iter(chat_list.keys()), None) if chat_list else None
                if new_active:
                    user_chats["active"] = new_active
                else:
                    new_chat_id = str(uuid.uuid4())[:8]
                    chat_list[new_chat_id] = {
                        "history": [{"role": "system", "content": "You are a friendly and helpful AI assistant."}],
                        "provider": None
                    }
                    user_chats["active"] = new_chat_id
            user_chats["chats"] = chat_list
            chats[user_id] = user_chats
            save_user_chats(chats)
            
            global stats
            stats['active_chats'] = max(0, stats['active_chats'] - 1)
            
            console.print(f"[yellow]üóëÔ∏è {tr('chat_deleted', lang)}: [bold]{chat_id}[/][/]")
            return True
        else:
            console.print(f"[red]‚ùå {tr('chat_not_found', lang)}[/]")
            return False
    except Exception:
        console.print(f"[red]‚ùå {tr('chat_not_found', lang)}[/]")
        return False

# –°–ø–∏—Å–æ–∫ —á–∞—Ç–æ–≤
def list_chats(user_id):
    lang = get_user_lang(user_id)
    user_id = str(user_id)
    chats = load_user_chats()
    user_chats = chats.get(user_id, {})
    chat_list = user_chats.get("chats", {})
    active_id = user_chats.get("active", "default")
    
    if not chat_list:
        console.print(f"[yellow]{tr('no_chats', lang)}[/]")
        return
    
    panel_text = ""
    for cid in chat_list:
        mark = "üü¢" if cid == active_id else "‚ö™"
        panel_text += f"[bold]{mark} {cid}[/]\n"
    
    console.print(Panel(
        panel_text.strip(),
        title=f"[bold cyan]{tr('your_chats', lang)}[/]",
        title_align="left",
        border_style="blue",
        padding=(0, 2),
        width=60
    ))

# –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å
def show_model(user_id):
    lang = get_user_lang(user_id)
    
    try:
        user_models = load_user_models()
        model = user_models.get(str(user_id), 'gpt-4o (default)')
        console.print(Panel(
            f"[bold]{model}[/]",
            title=f"[cyan]{tr('current_model_title', lang)}[/]",
            title_align="left",
            border_style="green",
            padding=(0, 2),
            width=60
        ))
    except Exception as e:
        logger.error(f"Model show error: {e}")
        console.print(f"[red]‚ùå {tr('model_error', lang)}[/]")

# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
def list_models(user_id):
    lang = get_user_lang(user_id)
    
    try:
        models_dict = get_supported_models()
        panel_text = ""
        
        for provider, models in models_dict.items():
            panel_text += f"\n[bold underline]{provider}:[/]\n"
            for model in sorted(models):
                panel_text += f"  - {model}\n"
        
        console.print(Panel(
            panel_text.strip(),
            title=f"[cyan]{tr('available_models', lang)} (g4f 0.5.7.5)[/]",
            title_align="left",
            border_style="magenta",
            padding=(0, 2),
            width=80
        ))
    except Exception as e:
        logger.error(f"Model list error: {e}")
        console.print(f"[red]‚ùå {tr('model_error', lang)}[/]")

# –°–ø–∏—Å–æ–∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
def list_providers(user_id):
    lang = get_user_lang(user_id)
    
    try:
        providers = init_providers()
        panel_text = "\n".join([f"- [bold]{provider.__name__}[/]" for provider in providers])
        
        console.print(Panel(
            f"{panel_text}\n\n[bold yellow]{tr('total_providers', lang)}: {len(providers)}[/]",
            title=f"[cyan]{tr('providers_title', lang)}[/]",
            title_align="left",
            border_style="yellow",
            padding=(0, 2),
            width=80
        ))
    except Exception as e:
        logger.error(f"Provider list error: {e}")
        console.print(f"[red]‚ùå {tr('model_error', lang)}[/]")

# –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
def system_status(user_id):
    lang = get_user_lang(user_id)
    
    try:
        # Get all supported models
        models_dict = get_supported_models()
        total_models = sum(len(models) for models in models_dict.values())
        
        # Get active providers count
        providers = init_providers()
        
        # Get current model
        user_models = load_user_models()
        current_model = user_models.get(str(user_id), 'gpt-4o (default)')
        
        # Format last activity time
        last_activity = time.strftime(tr('time_format', lang), time.localtime(stats['last_activity']))
        
        console.print(Panel(
            f"[bold]{tr('current_model_title', lang)}:[/] {current_model}\n"
            f"[bold]{tr('available_models', lang)}:[/] {total_models}\n"
            f"[bold]{tr('active_providers', lang)}:[/] {len(providers)}\n"
            f"[bold]{tr('active_chats', lang)}:[/] {stats['active_chats']}\n"
            f"[bold]{tr('total_messages', lang)}:[/] {stats['total_messages']}\n"
            f"[bold]{tr('saved_blocks', lang)}:[/] {stats['saved_code_blocks']}\n"
            f"[bold]{tr('last_activity', lang)}:[/] {last_activity}\n"
            f"[bold]System:[/] {sys.platform}\n"
            f"[bold]Python:[/] {sys.version.split()[0]}",
            title=f"[cyan]{tr('system_status_title', lang)}[/]",
            title_align="left",
            border_style="green",
            padding=(1, 2),
            width=70
        ))
    except Exception as e:
        logger.error(f"Status error: {e}")
        console.print(f"[red]‚ùå {tr('gen_error', lang)}[/]")

# –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
def show_stats(user_id):
    lang = get_user_lang(user_id)
    
    try:
        console.print(Panel(
            f"[bold]{tr('total_messages', lang)}:[/] {stats['total_messages']}\n"
            f"[bold]{tr('saved_blocks', lang)}:[/] {stats['saved_code_blocks']}\n"
            f"[bold]{tr('active_chats', lang)}:[/] {stats['active_chats']}\n"
            f"[bold]{tr('last_activity', lang)}:[/] {time.strftime(tr('time_format', lang), time.localtime(stats['last_activity']))}",
            title=f"[cyan]{tr('stats_title', lang)}[/]",
            title_align="left",
            border_style="blue",
            padding=(1, 2),
            width=60
        ))
    except Exception as e:
        logger.error(f"Stats error: {e}")
        console.print(f"[red]‚ùå {tr('gen_error', lang)}[/]")

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —á–∞—Ç–∞
def chat_loop():
    user_id = 1  # –î–ª—è –∫–æ–Ω—Å–æ–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    lang = get_user_lang(user_id)
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    os.makedirs("saved_code", exist_ok=True)
    
    chats = load_user_chats()
    user_chats = chats.get(str(user_id), {})
    active_id = user_chats.get("active", None)
    
    # –°–æ–∑–¥–∞–µ–º —á–∞—Ç –µ—Å–ª–∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ
    if not active_id or active_id not in user_chats.get("chats", {}):
        active_id = new_chat(user_id)
    
    # –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    console.print(Panel(
        f"[bold cyan]{tr('welcome', lang)}[/] (g4f v0.5.7.5)\n"
        f"[bold]{tr('developer', lang)}:[/] AiTechnologyDev\n"
        f"[bold]GitHub:[/] [link=https://github.com/AITechnologyDev]https://github.com/AITechnologyDev[/]",
        title=f"[cyan]{tr('welcome_menu', lang)}[/]",
        title_align="center",
        border_style="bright_cyan",
        padding=(1, 4),
        width=80
    ))
    
    show_help(user_id)
    init_providers()
    
    while True:
        try:
            console.print(f"\n[bold cyan]{tr('chat_prompt', lang)}:[/] ", end="")
            user_input = input().strip()
            
            if not user_input:
                continue
                
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats['total_messages'] += 1
            stats['last_activity'] = time.time()
                
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥
            if user_input.startswith('/'):
                cmd = user_input.split()[0].lower()
                
                if cmd == '/exit':
                    console.print(f"[bold yellow]{tr('exit_confirmation', lang)}[/]")
                    break
                    
                elif cmd == '/help':
                    show_help(user_id)
                    
                elif cmd == '/newchat':
                    active_id = new_chat(user_id)
                    
                elif cmd == '/usechat':
                    if len(user_input.split()) > 1:
                        chat_id = user_input.split()[1].strip()
                        if use_chat(user_id, chat_id):
                            active_id = chat_id
                    else:
                        console.print(f"[red]‚ùå {tr('chat_not_found', lang)}: /usechat <id>[/]")
                        
                elif cmd == '/delchat':
                    if len(user_input.split()) > 1:
                        chat_id = user_input.split()[1].strip()
                        del_chat(user_id, chat_id)
                    else:
                        console.print(f"[red]‚ùå {tr('chat_not_found', lang)}: /delchat <id>[/]")
                        
                elif cmd == '/chats':
                    list_chats(user_id)
                    
                elif cmd == '/setmodel':
                    if len(user_input.split()) > 1:
                        model_name = user_input.split(maxsplit=1)[1].strip()
                        set_model(user_id, model_name)
                    else:
                        console.print(f"[red]‚ùå {tr('model_error', lang)}: /setmodel <name>[/]")
                        
                elif cmd == '/mymodel':
                    show_model(user_id)
                    
                elif cmd == '/models':
                    list_models(user_id)
                    
                elif cmd == '/providers':
                    list_providers(user_id)
                    
                elif cmd == '/status':
                    system_status(user_id)
                    
                elif cmd == '/lang':
                    if len(user_input.split()) > 1:
                        new_lang = user_input.split()[1].strip().lower()
                        if new_lang in ['en', 'ru']:
                            save_user_lang(user_id, new_lang)
                            lang = new_lang
                            console.print(f"[green]‚úÖ {tr('lang_set', lang)}: {new_lang}[/]")
                        else:
                            console.print(f"[red]‚ùå {tr('invalid_lang', lang)}[/]")
                    else:
                        console.print(f"[yellow]Current language: {lang}[/]")
                
                elif cmd == '/stats':
                    show_stats(user_id)
                    
                else:
                    console.print(f"[red]‚ùå {tr('unknown_command', lang)}. /help {tr('help', lang).lower()}[/]")
                    
                continue
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
            all_chats = load_user_chats()
            user_chats = all_chats.get(str(user_id), {})
            chat_data = user_chats.get("chats", {}).get(active_id, {})
            history = chat_data.get("history", [])
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_message = {"role": "user", "content": user_input}
            history.append(user_message)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏
            chat_data["history"] = history
            user_chats.setdefault("chats", {})[active_id] = chat_data
            all_chats[str(user_id)] = user_chats
            save_user_chats(all_chats)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
            response_text = ""
            with Progress(
                SpinnerColumn(),
                TextColumn(f"[bold blue]{tr('generating', lang)}"),
                transient=True,
                console=console
            ) as progress:
                task = progress.add_task(tr('generating', lang), total=None)
                
                try:
                    response_text = generate_response(user_id, active_id, history)
                    
                    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
                    if response_text and not response_text.startswith("‚ö†Ô∏è"):
                        assistant_message = {"role": "assistant", "content": response_text}
                        history.append(assistant_message)
                        chat_data["history"] = history
                        user_chats.setdefault("chats", {})[active_id] = chat_data
                        all_chats[str(user_id)] = user_chats
                        save_user_chats(all_chats)
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π
                    response_text = process_model_thinking(response_text, lang)
                    
                    # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–¥–∞
                    response_text = save_code_blocks(response_text, active_id, lang)
                    
                    # –í—ã–≤–æ–¥ –æ—Ç–≤–µ—Ç–∞
                    console.print(f"\n[bold cyan]ü§ñ {tr('ai_prompt', lang)}:[/]")
                    try:
                        # –ü–æ–¥—Å–≤–µ—Ç–∫–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
                        highlighted = highlight_code(response_text)
                        console.print(highlighted)
                    except:
                        # –ü—Ä–æ—Å—Ç–æ–π –≤—ã–≤–æ–¥ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
                        console.print(response_text)
                    
                except Exception as e:
                    logger.error(f"Generation error: {e}")
                    console.print(f"\n[red]‚ö†Ô∏è {tr('gen_error', lang)}[/]")
                
                progress.update(task, completed=100)
                
        except KeyboardInterrupt:
            console.print(f"\n[bold yellow]{tr('exit', lang)}: /exit[/]")
        except Exception as e:
            logger.error(f"Main loop error: {e}")
            console.print(f"[red]‚ö†Ô∏è {tr('main_error', lang)}[/]")

if __name__ == '__main__':
    chat_loop()